{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "class Seq2SeqModel(object):\n",
    "    def __init__(self,vocab_size, word_embedding, input_len, output_len, params, train=True):\n",
    "        # Get the vocab size\n",
    "        # để làm gì ?\n",
    "        self.vocab_size=vocab_size \n",
    "\n",
    "        # Get hyper-parameters from params \n",
    "        # Để set các parameters      \n",
    "        self.num_layers=params['num_layers']\n",
    "        self.num_hiddens=params['num_hiddens']    \n",
    "        self.learning_rate = params['learning_rate']\n",
    "        self.keep_prob = params['keep_prob']\n",
    "        self.beam_width = params['beam_width']\n",
    "\n",
    "        # Using BasicLSTMCell as a cell unit\n",
    "        self.cell=tf.nn.rnn_cell.LSTMCell\n",
    "\n",
    "        # Define Place holders for the model\n",
    "        self.batch_size=tf.placeholder(tf.int32,(),name=\"batch_size\")\n",
    "        self.global_step = tf.Variable(0, trainable=False) # False means not adding the variable to the graph collection \n",
    "\n",
    "        # place holders for encoder\n",
    "        self.inputSeq=tf.placeholder(tf.int32,[None,input_len])\n",
    "        # mỗi giá trị trong vector là độ dài thực tế của input seq encoder (khi chưa padding)\n",
    "        # sd độ dài thực tế để giảm thiểu sai số khi thực hiện tính toán với cả padding\n",
    "        self.inputSeq_len=tf.placeholder(tf.int32, [None]) # Need to define the Shape as required in tf.contrib.seq2seq.tile_batch\n",
    "\n",
    "        # place holders for decoder\n",
    "        self.decoder_input=tf.placeholder(tf.int32,[None,output_len])\n",
    "        # mỗi giá trị trong vector là độ dài thực tế của input seq decoder (khi chưa padding)\n",
    "        # sd độ dài thực tế để giảm thiểu sai số khi thực hiện tính toán với cả padding\n",
    "        self.decoder_len=tf.placeholder(tf.int32, [None])\n",
    "        self.decoder_target=tf.placeholder(tf.int32,[None,output_len])\n",
    "\n",
    "        # Define projection_layer\n",
    "        # để chuyển ouput của Decoder về dạng Logits Vector với số lượng Dimension tương ứng với Vocab size.\n",
    "        # Từ đó có thể xác định được ouput word tương ứng.\n",
    "        self.projection_layer = tf.layers.Dense(self.vocab_size, use_bias=False)\n",
    "\n",
    "        # Define the Embedding layer\n",
    "        with tf.name_scope(\"embedding\"):\n",
    "            self.embeddings=tf.get_variable(\"embeddings\",initializer=tf.constant(word_embedding,dtype=tf.float32))\n",
    "\n",
    "            # map the int value with its embeddings\n",
    "            # dùng tf.nn.embedding_lookup để tra cứu trong ma trận nhúng và trả về các vectơ cho các từ đầu vào\n",
    "        \n",
    "            input_emb=tf.nn.embedding_lookup(self.embeddings,self.inputSeq) #[seq_length * embed_dim]\n",
    "            decoder_input_emb=tf.nn.embedding_lookup(self.embeddings,self.decoder_input)\n",
    "\n",
    "            # Convert from batch_size*seq_len*embedding to seq_len*batch_size*embedding to feed data with timestep      \n",
    "            # But, we need to set time_major=True during Training\n",
    "            # hầu hết dl tensorflow đều có dạng batch_major\n",
    "            # dùng tf.transpose để chuyển input từ dạng batch_major sang time_major để giúp tiết kiệm thời gian trong quá trình huấn luyện -> tiết kiệm bằng cách ???\n",
    "            self.encoder_inputEmb = tf.transpose(input_emb, perm=[1, 0, 2])\n",
    "            self.decoder_inputEmb = tf.transpose(decoder_input_emb, perm=[1, 0, 2])\n",
    "\n",
    "        # Define the Encoder\n",
    "        with tf.name_scope(\"encoder\"):      \n",
    "            # Create RNN Cell for forward and backward direction\n",
    "            fw_cells=list()\n",
    "            bw_cells=list()\n",
    "            for i in range(self.num_layers):\n",
    "                fw_cell= self.cell(self.num_hiddens)\n",
    "                bw_cell= self.cell(self.num_hiddens)\n",
    "\n",
    "                # Add Dropout\n",
    "                # để hạn chế overfitting trong quá trình train\n",
    "                # DropoutWrapper được sử dụng để thiết lập giá trị Drop Out cho các LSTM cell\n",
    "                fw_cell=rnn.DropoutWrapper(fw_cell,output_keep_prob=self.keep_prob)\n",
    "                bw_cell=rnn.DropoutWrapper(bw_cell,output_keep_prob=self.keep_prob)\n",
    "\n",
    "                # Add cell to the list\n",
    "                fw_cells.append(fw_cell)\n",
    "                bw_cells.append(bw_cell)\n",
    "\n",
    "\n",
    "            # Build a multi bi-directional model from fw_cells and bw_cells\n",
    "            # sử dụng tf.contrib.rnn.stack_bidirectional_dynamic_rnn để kết hợp các cells này thành một mô hình Multi layer Bi-directional LSTM.\n",
    "            outputs, encoder_state_fw, encoder_state_bw = tf.contrib.rnn.stack_bidirectional_dynamic_rnn(\n",
    "              cells_fw=fw_cells, cells_bw=bw_cells,inputs=self.encoder_inputEmb,time_major=True, sequence_length=self.inputSeq_len, dtype=tf.float32)\n",
    "\n",
    "            # The ouput of Encoder (time major)\n",
    "            self.encoder_outputs=outputs # kích thước [max_time, batch_size, cell_fw.output_size + cell_bw.output_size]\n",
    "\n",
    "            # Use the final state of the last layer as encoder_final_state \n",
    "            # encoder_state_fw là 1 tuple của các final state tại mỗi forward layer chứa giá trị Cell state và Hidden state của layer đó\n",
    "\n",
    "            encoder_state_c = tf.concat((encoder_state_fw[-1].c, encoder_state_bw[-1].c), 1)\n",
    "            encoder_state_h = tf.concat((encoder_state_fw[-1].h, encoder_state_bw[-1].h), 1)\n",
    "            self.encoder_final_state = rnn.LSTMStateTuple(c=encoder_state_c, h=encoder_state_h) # kích thước [batch_size, cell_fw.output_size + cell_bw.output_size]\n",
    "      \n",
    "        # Define the Decoder for training\n",
    "        with tf.name_scope(\"decoder\"):\n",
    "            # Define Decoder cell\n",
    "            # sd final state của Encoder làm initial state cho Decoder              \n",
    "            # nên số lượng hidden units của Decoder phải bằng với kích thước của Encoder final state\n",
    "            decoder_num_hiddens =self.num_hiddens * 2 # As we use bi-directional RNN\n",
    "            decoder_cell=self.cell(decoder_num_hiddens)\n",
    "\n",
    "            # 2 TH: training (huấn luyện mô hình) và inference (tính prediction)\n",
    "            # khi training, chúng ta sử dụng giá trị output thực làm input cho Decoder.\n",
    "            # khi inference, chúng ta không biết giá trị thực này, do đó ta phải sử dụng GreedySearch hoặc BeamSearch để tìm giá trị output hợp lý nhất.\n",
    "            # Training mode \n",
    "            if(train):\n",
    "                # Convert from time major to batch major \n",
    "                attention_states = tf.transpose(self.encoder_outputs, [1, 0, 2]) #[batch_size, max_time, cell_fw.output_size+ cell_bw.output_size]\n",
    "\n",
    "                # Decoder with attention      \n",
    "                attention=tf.contrib.seq2seq.BahdanauAttention(num_units=decoder_num_hiddens, memory=attention_states, memory_sequence_length=self.inputSeq_len,normalize=True)\n",
    "                attention_decoder_cell= tf.contrib.seq2seq.AttentionWrapper(cell=decoder_cell,attention_mechanism=attention,attention_layer_size=decoder_num_hiddens)\n",
    "\n",
    "                # Use the final state of encoder as the initial state of the decoder\n",
    "                decoder_initial_state = attention_decoder_cell.zero_state(dtype=tf.float32, batch_size=self.batch_size)\n",
    "                decoder_initial_state = decoder_initial_state.clone(cell_state=self.encoder_final_state ) # [batch_size, cell_fw.output_size + cell_bw.output_size]\n",
    "\n",
    "                # Use TrainingHelper to train the Model \n",
    "                training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=self.decoder_inputEmb,sequence_length=self.decoder_len, time_major=True)\n",
    "                decoder = tf.contrib.seq2seq.BasicDecoder(cell=attention_decoder_cell,helper=training_helper,initial_state=decoder_initial_state,output_layer=self.projection_layer)\n",
    "                logits, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder, output_time_major=True,maximum_iterations=output_len)\n",
    "\n",
    "\n",
    "                # Convert from time major to batch major \n",
    "                self.training_logits = tf.transpose(logits.rnn_output, perm=[1, 0, 2])\n",
    "\n",
    "                # Adding zero to make sure training_logits has shape: [batch_size, sequence_length, num_decoder_symbols]\n",
    "                # các output sequences của Decoder có thể có độ dài khác nhau \n",
    "                # ta padding 0 để training_logits có kích thước  [batch_size, sequence_length, vocab_size]\n",
    "                self.training_logits = tf.concat([self.training_logits, tf.zeros([self.batch_size, output_len - tf.shape(self.training_logits)[1], self.vocab_size])], axis=1)\n",
    "\n",
    "            # Inference mode \n",
    "            # giai đoạn sử dụng model để dự đoán output\n",
    "            else:\n",
    "                # Using Beam search\n",
    "                # sử dụng tf.contrib.seq2seq.tile_batch để chuyển dữ liệu về dạng beam_width\n",
    "                \n",
    "                tiled_encoder_outputs = tf.contrib.seq2seq.tile_batch(tf.transpose(self.encoder_outputs, perm=[1, 0, 2]), multiplier=self.beam_width) # kích thước [batch_size * multiplier, ...]\n",
    "                tiled_encoder_final_state=tf.contrib.seq2seq.tile_batch(self.encoder_final_state, multiplier=self.beam_width)\n",
    "                tiled_inputSeq_len=tf.contrib.seq2seq.tile_batch(self.inputSeq_len, multiplier=self.beam_width)\n",
    "\n",
    "                # Decoder with attention with Beam search\n",
    "                attention=tf.contrib.seq2seq.BahdanauAttention(num_units=decoder_num_hiddens, memory=tiled_encoder_outputs, memory_sequence_length=tiled_inputSeq_len,normalize=True)\n",
    "                attention_decoder_cell= tf.contrib.seq2seq.AttentionWrapper(cell=decoder_cell,attention_mechanism=attention,attention_layer_size=decoder_num_hiddens)\n",
    "\n",
    "                # Use the final state of encoder as the initial state of the decoder\n",
    "                decoder_initial_state = attention_decoder_cell.zero_state(dtype=tf.float32, batch_size=self.batch_size * self.beam_width)\n",
    "                decoder_initial_state = decoder_initial_state.clone(cell_state=tiled_encoder_final_state)\n",
    "\n",
    "                # Build a Decoder with Beam Search\n",
    "                # sử dụng BeamSearchDecoder và seq2seq.dynamic_decode để tính kết quả prediction\n",
    "                \n",
    "                # tại sao là tf.constant(3) ??  \n",
    "                              beamSearch_decoder=tf.contrib.seq2seq.BeamSearchDecoder(          \n",
    "                    cell=attention_decoder_cell,\n",
    "                    embedding=self.embeddings,\n",
    "                    start_tokens=tf.fill([self.batch_size],tf.constant(2)),\n",
    "                    end_token=tf.constant(3),\n",
    "                    initial_state=decoder_initial_state,\n",
    "                    beam_width=self.beam_width,\n",
    "                    output_layer=self.projection_layer  \n",
    "                )\n",
    "\n",
    "                # Perform dynamic decoding with beamSearch_decoder\n",
    "                # outputs là một FinalBeamSearchDecoderOutput với predicted_ids là kết quả prediction có kích thước là [seq_len, batch_size, beam_width] khi time_major=True\n",
    "                outputs, _ , _ =tf.contrib.seq2seq.dynamic_decode(decoder=beamSearch_decoder,maximum_iterations= output_len,output_time_major=True)\n",
    "\n",
    "                # Convert from seq_len*batch_size*beam_width to batch_size*beam_width*seq_len\n",
    "                outputs=tf.transpose(outputs.predicted_ids, perm=[1, 2, 0])\n",
    "\n",
    "                # Take the first beam (best result) as Decoder ouput \n",
    "                # Beams được sắp xếp theo thứ tự giảm dần từ kết quả tốt nhất\n",
    "                self.decoder_outputs=outputs[:,0,:]\n",
    "\n",
    "        with tf.name_scope(\"optimization\"):\n",
    "            # Used for Training mode only \n",
    "            if(train):\n",
    "                # Caculate loss value \n",
    "                # \n",
    "                masks = tf.sequence_mask(lengths=self.decoder_len,maxlen=output_len, dtype=tf.float32)   \n",
    "                \n",
    "                              \n",
    "                # sd tf.contrib.seq2seq.sequence_loss để tính loss function bằng cách\n",
    "                self.loss = tf.contrib.seq2seq.sequence_loss(logits=self.training_logits,targets=self.decoder_target,weights=masks)\n",
    "\n",
    "                # Using AdamOptimizer\n",
    "                # dùng AdamOptimizer để update model bằng cách ???\n",
    "                optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "                # Compute gradient \n",
    "                gradients = optimizer.compute_gradients(self.loss)\n",
    "                # Apply Gradient Clipping\n",
    "                # Gradient Clipping để giữ giá trị gradient trong khoảng [-5, 5] \n",
    "                gradients_clipping = [(tf.clip_by_value(grad, clip_value_min=-5., clip_value_max=5.), var) for grad, var in gradients if grad is not None]\n",
    "\n",
    "                # Apply gradients to variables\n",
    "                self.train_update = optimizer.apply_gradients(gradients_clipping, global_step=self.global_step)\n",
    "        \n",
    "print(\"done\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}